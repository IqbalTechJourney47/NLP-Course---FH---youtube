{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7acdf58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: inltk in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (0.9)\n",
      "Requirement already satisfied: aiohttp>=3.5.4 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (3.8.6)\n",
      "Requirement already satisfied: fastai==1.0.57 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (1.0.57)\n",
      "Requirement already satisfied: pandas in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (2.1.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (0.1.99)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (4.12.2)\n",
      "Requirement already satisfied: fastprogress>=0.1.19 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (1.0.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (23.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (1.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (2.31.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (9.4.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (6.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (1.25.2)\n",
      "Requirement already satisfied: spacy>=2.0.18 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (3.7.1)\n",
      "Requirement already satisfied: nvidia-ml-py3 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (7.352.0)\n",
      "Requirement already satisfied: numexpr in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (2.8.7)\n",
      "Requirement already satisfied: bottleneck in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (1.3.7)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (3.8.0)\n",
      "Requirement already satisfied: async-timeout>=3.0.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (4.0.3)\n",
      "Requirement already satisfied: typing in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (3.7.4.3)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from fastai==1.0.57->inltk) (2.1.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from fastai==1.0.57->inltk) (0.16.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from aiohttp>=3.5.4->inltk) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from aiohttp>=3.5.4->inltk) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from aiohttp>=3.5.4->inltk) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from aiohttp>=3.5.4->inltk) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from aiohttp>=3.5.4->inltk) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from aiohttp>=3.5.4->inltk) (2.0.4)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (0.10.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (1.0.10)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (2.4.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (1.1.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (3.1.2)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (0.3.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (3.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (1.0.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (65.6.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (2.4.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (6.4.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (2.0.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (4.65.0)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (0.9.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from requests->inltk) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from requests->inltk) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from requests->inltk) (2.10)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from beautifulsoup4->inltk) (2.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from matplotlib->inltk) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from matplotlib->inltk) (3.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from matplotlib->inltk) (1.4.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from matplotlib->inltk) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from matplotlib->inltk) (4.42.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from matplotlib->inltk) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from pandas->inltk) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from pandas->inltk) (2022.7)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.18->inltk) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.18->inltk) (4.7.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.18->inltk) (0.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->inltk) (1.16.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy>=2.0.18->inltk) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy>=2.0.18->inltk) (0.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from torch>=1.0.0->fastai==1.0.57->inltk) (2023.10.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from torch>=1.0.0->fastai==1.0.57->inltk) (3.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from torch>=1.0.0->fastai==1.0.57->inltk) (1.12)\n",
      "Requirement already satisfied: filelock in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from torch>=1.0.0->fastai==1.0.57->inltk) (3.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy>=2.0.18->inltk) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy>=2.0.18->inltk) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.16.0,>=0.7.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy>=2.0.18->inltk) (0.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from jinja2->spacy>=2.0.18->inltk) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from sympy->torch>=1.0.0->fastai==1.0.57->inltk) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement torch==1.3.1+cpu (from versions: 1.11.0, 1.11.0+cpu, 1.11.0+cu113, 1.11.0+cu115, 1.12.0, 1.12.0+cpu, 1.12.0+cu113, 1.12.0+cu116, 1.12.1, 1.12.1+cpu, 1.12.1+cu113, 1.12.1+cu116, 1.13.0, 1.13.0+cpu, 1.13.0+cu116, 1.13.0+cu117, 1.13.1, 1.13.1+cpu, 1.13.1+cu116, 1.13.1+cu117, 2.0.0, 2.0.0+cpu, 2.0.0+cu117, 2.0.0+cu118, 2.0.1, 2.0.1+cpu, 2.0.1+cu117, 2.0.1+cu118, 2.1.0, 2.1.0+cpu, 2.1.0+cu118, 2.1.0+cu121)\n",
      "ERROR: No matching distribution found for torch==1.3.1+cpu\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install inltk\n",
    "!pip install torch==1.3.1+cpu -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcdf8ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\muhammad iqbal\\anaconda3\\envs\\pythonurdu\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\muhammad iqbal\\anaconda3\\envs\\pythonurdu\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\muhammad iqbal\\appdata\\roaming\\python\\python39\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\muhammad iqbal\\anaconda3\\envs\\pythonurdu\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\muhammad iqbal\\anaconda3\\envs\\pythonurdu\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\muhammad iqbal\\anaconda3\\envs\\pythonurdu\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\muhammad iqbal\\anaconda3\\envs\\pythonurdu\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\muhammad iqbal\\anaconda3\\envs\\pythonurdu\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\muhammad iqbal\\anaconda3\\envs\\pythonurdu\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0746d0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: inltk in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (0.9)\n",
      "Requirement already satisfied: bottleneck in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (1.3.7)\n",
      "Requirement already satisfied: packaging in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (23.1)\n",
      "Requirement already satisfied: numexpr in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (2.8.7)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (3.8.0)\n",
      "Requirement already satisfied: fastai==1.0.57 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (1.0.57)\n",
      "Requirement already satisfied: fastprogress>=0.1.19 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (1.0.3)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (0.1.99)\n",
      "Requirement already satisfied: Pillow in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (9.4.0)\n",
      "Requirement already satisfied: nvidia-ml-py3 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (7.352.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (1.25.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (1.11.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (6.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (2.1.0)\n",
      "Requirement already satisfied: aiohttp>=3.5.4 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (3.8.6)\n",
      "Requirement already satisfied: requests in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (2.31.0)\n",
      "Requirement already satisfied: async-timeout>=3.0.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (4.0.3)\n",
      "Requirement already satisfied: typing in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (3.7.4.3)\n",
      "Requirement already satisfied: spacy>=2.0.18 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from inltk) (3.7.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from fastai==1.0.57->inltk) (2.1.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from fastai==1.0.57->inltk) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from aiohttp>=3.5.4->inltk) (2.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from aiohttp>=3.5.4->inltk) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from aiohttp>=3.5.4->inltk) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from aiohttp>=3.5.4->inltk) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from aiohttp>=3.5.4->inltk) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from aiohttp>=3.5.4->inltk) (1.3.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (6.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (65.6.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (3.0.12)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (0.3.2)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (8.2.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (2.4.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (2.4.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (4.65.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (3.0.9)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (1.0.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (1.1.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (0.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (3.1.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (2.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (1.0.5)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (0.10.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->inltk) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from requests->inltk) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from requests->inltk) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from requests->inltk) (1.26.16)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from beautifulsoup4->inltk) (2.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from matplotlib->inltk) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from matplotlib->inltk) (3.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from matplotlib->inltk) (1.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from matplotlib->inltk) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from matplotlib->inltk) (4.42.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from matplotlib->inltk) (1.1.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from pandas->inltk) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from pandas->inltk) (2022.7)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.18->inltk) (2.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.18->inltk) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.18->inltk) (4.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->inltk) (1.16.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy>=2.0.18->inltk) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy>=2.0.18->inltk) (0.1.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from torch>=1.0.0->fastai==1.0.57->inltk) (3.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from torch>=1.0.0->fastai==1.0.57->inltk) (2023.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from torch>=1.0.0->fastai==1.0.57->inltk) (1.12)\n",
      "Requirement already satisfied: filelock in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from torch>=1.0.0->fastai==1.0.57->inltk) (3.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy>=2.0.18->inltk) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy>=2.0.18->inltk) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.16.0,>=0.7.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy>=2.0.18->inltk) (0.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from jinja2->spacy>=2.0.18->inltk) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from sympy->torch>=1.0.0->fastai==1.0.57->inltk) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from torch) (3.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: fsspec in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\muhammad iqbal\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade inltk\n",
    "!pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b5069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import abc,  Counter, defaultdict, namedtuple, OrderedDict\n",
    "#from collections.abc import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60ae7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the language\n",
    "\n",
    "from inltk.inltk import setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6c083cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mur\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\inltk\\inltk.py:33\u001b[0m, in \u001b[0;36msetup\u001b[1;34m(language_code)\u001b[0m\n\u001b[0;32m     31\u001b[0m loop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n\u001b[0;32m     32\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [asyncio\u001b[38;5;241m.\u001b[39mensure_future(download(language_code))]\n\u001b[1;32m---> 33\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     34\u001b[0m loop\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\asyncio\\base_events.py:623\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \n\u001b[0;32m    614\u001b[0m \u001b[38;5;124;03mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;124;03mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m--> 623\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    625\u001b[0m new_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m futures\u001b[38;5;241m.\u001b[39misfuture(future)\n\u001b[0;32m    626\u001b[0m future \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mensure_future(future, loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\asyncio\\base_events.py:583\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_running\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[1;32m--> 583\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    585\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    586\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot run the event loop while another loop is running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "setup('ur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5645a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁',\n",
       " 'ُ',\n",
       " 'اس',\n",
       " '▁سے',\n",
       " '▁س',\n",
       " 'ُ',\n",
       " 'ن',\n",
       " 'کر',\n",
       " '▁جو',\n",
       " '▁پ',\n",
       " 'َ',\n",
       " 'ی',\n",
       " 'غا',\n",
       " 'م',\n",
       " '▁ہم',\n",
       " '▁ت',\n",
       " 'ُ',\n",
       " 'م',\n",
       " 'ہیں',\n",
       " '▁دیتے',\n",
       " '▁ہیں',\n",
       " '▁وہ',\n",
       " '▁یہ',\n",
       " '▁ہے',\n",
       " '▁کہ',\n",
       " '▁خ',\n",
       " 'ُ',\n",
       " 'دا',\n",
       " '▁ن',\n",
       " 'ُ',\n",
       " 'ور',\n",
       " '▁ہے',\n",
       " '▁اور',\n",
       " '▁ا',\n",
       " 'ُ',\n",
       " 'س',\n",
       " '▁میں',\n",
       " '▁ذرا',\n",
       " '▁بھی',\n",
       " '▁تار',\n",
       " 'ِ',\n",
       " 'ی',\n",
       " 'کی',\n",
       " '▁نہیں',\n",
       " '▁۔']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inltk.inltk import tokenize\n",
    "\n",
    "urdu_text = \"ُاس سے سُنکر جو پَیغام ہم تُمہیں دیتے ہیں وہ یہ ہے کہ خُدا نُور ہے اور اُس میں ذرا بھی تارِیکی نہیں ۔\"\n",
    "\n",
    "tokenize(urdu_text, \"ur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55947007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁میرا',\n",
       " '▁نام',\n",
       " '▁رابع',\n",
       " 'ہ',\n",
       " '/',\n",
       " 'ر',\n",
       " 'بیعہ',\n",
       " '▁اقبال',\n",
       " '▁ہے۔',\n",
       " '▁میں',\n",
       " '▁لاہور',\n",
       " '،',\n",
       " '▁پاکستان',\n",
       " '▁میں',\n",
       " '▁رہتی',\n",
       " '▁ہوں۔',\n",
       " '▁لاہور',\n",
       " '▁پاکستان',\n",
       " '▁کے',\n",
       " '▁مشہور',\n",
       " '▁شہروں',\n",
       " '▁میں',\n",
       " '▁سے',\n",
       " '▁ایک',\n",
       " '▁ہے۔']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inltk.inltk import tokenize\n",
    "\n",
    "urdu_text = 'میرا نام رابعہ/ربیعہ اقبال ہے۔ میں لاہور، پاکستان میں رہتی ہوں۔ لاہور پاکستان کے مشہور شہروں میں سے ایک ہے۔'\n",
    "\n",
    "tokenize(urdu_text, \"ur\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e28d086",
   "metadata": {},
   "source": [
    "### Get Embedding Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55664607",
   "metadata": {},
   "source": [
    "This returns an array of \"Embedding Vectors\", containing 400 Dimensional representation for every token in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5be724c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LSTM' object has no attribute '_flat_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_embedding_vectors\n\u001b[1;32m----> 2\u001b[0m vectors \u001b[38;5;241m=\u001b[39m \u001b[43mget_embedding_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43murdu_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mur\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\inltk\\inltk.py:100\u001b[0m, in \u001b[0;36mget_embedding_vectors\u001b[1;34m(input, language_code)\u001b[0m\n\u001b[0;32m     98\u001b[0m defaults\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     99\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m--> 100\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mload_learner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlanguage_code\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m encoder \u001b[38;5;241m=\u001b[39m get_model(learn\u001b[38;5;241m.\u001b[39mmodel)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    102\u001b[0m encoder\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\fastai\\basic_train.py:619\u001b[0m, in \u001b[0;36mload_learner\u001b[1;34m(path, file, test, **db_kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoad a `Learner` object saved with `export_state` in `path/file` with empty data, optionally add `test` and load on `cpu`. `file` can be file-like (file or buffer)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    618\u001b[0m source \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m/\u001b[39mfile \u001b[38;5;28;01mif\u001b[39;00m is_pathlike(file) \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[1;32m--> 619\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m defaults\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(source)\n\u001b[0;32m    620\u001b[0m model \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    621\u001b[0m src \u001b[38;5;241m=\u001b[39m LabelLists\u001b[38;5;241m.\u001b[39mload_state(path, state\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\serialization.py:1028\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1027\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1028\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\serialization.py:1256\u001b[0m, in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1254\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1255\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1256\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1258\u001b[0m deserialized_storage_keys \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1260\u001b[0m offset \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;28;01mif\u001b[39;00m f_should_read_directly \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:349\u001b[0m, in \u001b[0;36mRNNBase.__setstate__\u001b[1;34m(self, d)\u001b[0m\n\u001b[0;32m    344\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights_names\u001b[38;5;241m.\u001b[39mextend(weights[:\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    346\u001b[0m                           \u001b[38;5;28;01mfor\u001b[39;00m wn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights_names]\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weight_refs \u001b[38;5;241m=\u001b[39m [weakref\u001b[38;5;241m.\u001b[39mref(w) \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 349\u001b[0m                           \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LSTM' object has no attribute '_flat_weights'"
     ]
    }
   ],
   "source": [
    "from inltk.inltk import get_embedding_vectors\n",
    "vectors = get_embedding_vectors(urdu_text, \"ur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea028a19",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mvectors\u001b[49m[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectors' is not defined"
     ]
    }
   ],
   "source": [
    "vectors[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d91dc51",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mvectors\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectors' is not defined"
     ]
    }
   ],
   "source": [
    "len(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824011c5",
   "metadata": {},
   "source": [
    "### Predict Next 'n' words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e6bc98f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LSTM' object has no attribute '_flat_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m predict_next_words\n\u001b[1;32m----> 2\u001b[0m \u001b[43mpredict_next_words\u001b[49m\u001b[43m(\u001b[49m\u001b[43murdu_text\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mur\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\inltk\\inltk.py:50\u001b[0m, in \u001b[0;36mpredict_next_words\u001b[1;34m(input, n_words, language_code, randomness)\u001b[0m\n\u001b[0;32m     48\u001b[0m defaults\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     49\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m---> 50\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mload_learner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlanguage_code\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m output \u001b[38;5;241m=\u001b[39m learn\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28minput\u001b[39m, n_words, randomness)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# UTF-8 encoding takes care of both LTR and RTL languages\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\fastai\\basic_train.py:619\u001b[0m, in \u001b[0;36mload_learner\u001b[1;34m(path, file, test, **db_kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoad a `Learner` object saved with `export_state` in `path/file` with empty data, optionally add `test` and load on `cpu`. `file` can be file-like (file or buffer)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    618\u001b[0m source \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m/\u001b[39mfile \u001b[38;5;28;01mif\u001b[39;00m is_pathlike(file) \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[1;32m--> 619\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m defaults\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(source)\n\u001b[0;32m    620\u001b[0m model \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    621\u001b[0m src \u001b[38;5;241m=\u001b[39m LabelLists\u001b[38;5;241m.\u001b[39mload_state(path, state\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\serialization.py:1028\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1027\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1028\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\serialization.py:1256\u001b[0m, in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1254\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1255\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1256\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1258\u001b[0m deserialized_storage_keys \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1260\u001b[0m offset \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;28;01mif\u001b[39;00m f_should_read_directly \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:349\u001b[0m, in \u001b[0;36mRNNBase.__setstate__\u001b[1;34m(self, d)\u001b[0m\n\u001b[0;32m    344\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights_names\u001b[38;5;241m.\u001b[39mextend(weights[:\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    346\u001b[0m                           \u001b[38;5;28;01mfor\u001b[39;00m wn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights_names]\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weight_refs \u001b[38;5;241m=\u001b[39m [weakref\u001b[38;5;241m.\u001b[39mref(w) \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 349\u001b[0m                           \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LSTM' object has no attribute '_flat_weights'"
     ]
    }
   ],
   "source": [
    "from inltk.inltk import predict_next_words\n",
    "predict_next_words(urdu_text,1,\"ur\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3922498d",
   "metadata": {},
   "source": [
    "### Identify Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d2f1f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inltk.inltk import identify_language\n",
    "identify_language('Hi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d374a95",
   "metadata": {},
   "source": [
    "### Get sentence encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d30f3df",
   "metadata": {},
   "source": [
    "get_sentence_encoding returns 400 dimensional encoding of the sentence from ULMFiT\n",
    "\n",
    "LM Encoder of trained in repositories linked below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e386e54",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LSTM' object has no attribute '_flat_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_sentence_encoding\n\u001b[1;32m----> 2\u001b[0m encoding \u001b[38;5;241m=\u001b[39m \u001b[43mget_sentence_encoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43murdu_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mur\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\inltk\\inltk.py:118\u001b[0m, in \u001b[0;36mget_sentence_encoding\u001b[1;34m(input, language_code)\u001b[0m\n\u001b[0;32m    116\u001b[0m defaults\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    117\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m--> 118\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mload_learner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlanguage_code\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m encoder \u001b[38;5;241m=\u001b[39m learn\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    120\u001b[0m encoder\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\fastai\\basic_train.py:619\u001b[0m, in \u001b[0;36mload_learner\u001b[1;34m(path, file, test, **db_kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoad a `Learner` object saved with `export_state` in `path/file` with empty data, optionally add `test` and load on `cpu`. `file` can be file-like (file or buffer)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    618\u001b[0m source \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m/\u001b[39mfile \u001b[38;5;28;01mif\u001b[39;00m is_pathlike(file) \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[1;32m--> 619\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m defaults\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(source)\n\u001b[0;32m    620\u001b[0m model \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    621\u001b[0m src \u001b[38;5;241m=\u001b[39m LabelLists\u001b[38;5;241m.\u001b[39mload_state(path, state\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\serialization.py:1028\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1027\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1028\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\serialization.py:1256\u001b[0m, in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1254\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1255\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1256\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1258\u001b[0m deserialized_storage_keys \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1260\u001b[0m offset \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;28;01mif\u001b[39;00m f_should_read_directly \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:349\u001b[0m, in \u001b[0;36mRNNBase.__setstate__\u001b[1;34m(self, d)\u001b[0m\n\u001b[0;32m    344\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights_names\u001b[38;5;241m.\u001b[39mextend(weights[:\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    346\u001b[0m                           \u001b[38;5;28;01mfor\u001b[39;00m wn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights_names]\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weight_refs \u001b[38;5;241m=\u001b[39m [weakref\u001b[38;5;241m.\u001b[39mref(w) \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 349\u001b[0m                           \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LSTM' object has no attribute '_flat_weights'"
     ]
    }
   ],
   "source": [
    "from inltk.inltk import get_sentence_encoding\n",
    "encoding = get_sentence_encoding(urdu_text, \"ur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "425d92ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mencoding\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'encoding' is not defined"
     ]
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "258197a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mencoding\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'encoding' is not defined"
     ]
    }
   ],
   "source": [
    "encoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc36546f",
   "metadata": {},
   "source": [
    "### Get Sentence Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3867ff",
   "metadata": {},
   "source": [
    "get_sentence_similarity returns similarity between two sentences by calculating cosine similarity (default comparison function) between the encoding vectors of two sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d536f8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LSTM' object has no attribute '_flat_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get Sentence Similarity\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_sentence_similarity\n\u001b[1;32m----> 4\u001b[0m \u001b[43mget_sentence_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mلاہور کے مختلف علاقوں میں بارش\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mمختلف علاقوں میں بارش\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mur\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# similarity of encodings is calculted by using cmp function whose default is cosine similarity\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\inltk\\inltk.py:127\u001b[0m, in \u001b[0;36mget_sentence_similarity\u001b[1;34m(sen1, sen2, language_code, cmp)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_sentence_similarity\u001b[39m(sen1: \u001b[38;5;28mstr\u001b[39m, sen2: \u001b[38;5;28mstr\u001b[39m, language_code: \u001b[38;5;28mstr\u001b[39m, cmp: Callable \u001b[38;5;241m=\u001b[39m cos_sim):\n\u001b[0;32m    126\u001b[0m     check_input_language(language_code)\n\u001b[1;32m--> 127\u001b[0m     enc1 \u001b[38;5;241m=\u001b[39m \u001b[43mget_sentence_encoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msen1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     enc2 \u001b[38;5;241m=\u001b[39m get_sentence_encoding(sen2, language_code)\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cmp(enc1, enc2)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\inltk\\inltk.py:118\u001b[0m, in \u001b[0;36mget_sentence_encoding\u001b[1;34m(input, language_code)\u001b[0m\n\u001b[0;32m    116\u001b[0m defaults\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    117\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m--> 118\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mload_learner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlanguage_code\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m encoder \u001b[38;5;241m=\u001b[39m learn\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    120\u001b[0m encoder\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\fastai\\basic_train.py:619\u001b[0m, in \u001b[0;36mload_learner\u001b[1;34m(path, file, test, **db_kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoad a `Learner` object saved with `export_state` in `path/file` with empty data, optionally add `test` and load on `cpu`. `file` can be file-like (file or buffer)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    618\u001b[0m source \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m/\u001b[39mfile \u001b[38;5;28;01mif\u001b[39;00m is_pathlike(file) \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[1;32m--> 619\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m defaults\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(source)\n\u001b[0;32m    620\u001b[0m model \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    621\u001b[0m src \u001b[38;5;241m=\u001b[39m LabelLists\u001b[38;5;241m.\u001b[39mload_state(path, state\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\serialization.py:1028\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1027\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1028\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\serialization.py:1256\u001b[0m, in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1254\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1255\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1256\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1258\u001b[0m deserialized_storage_keys \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1260\u001b[0m offset \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;28;01mif\u001b[39;00m f_should_read_directly \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:349\u001b[0m, in \u001b[0;36mRNNBase.__setstate__\u001b[1;34m(self, d)\u001b[0m\n\u001b[0;32m    344\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights_names\u001b[38;5;241m.\u001b[39mextend(weights[:\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    346\u001b[0m                           \u001b[38;5;28;01mfor\u001b[39;00m wn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights_names]\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weight_refs \u001b[38;5;241m=\u001b[39m [weakref\u001b[38;5;241m.\u001b[39mref(w) \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 349\u001b[0m                           \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LSTM' object has no attribute '_flat_weights'"
     ]
    }
   ],
   "source": [
    "# Get Sentence Similarity\n",
    "\n",
    "from inltk.inltk import get_sentence_similarity\n",
    "get_sentence_similarity('لاہور کے مختلف علاقوں میں بارش' , 'مختلف علاقوں میں بارش', 'ur')\n",
    "\n",
    "# similarity of encodings is calculted by using cmp function whose default is cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69b6ec74",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LSTM' object has no attribute '_flat_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_similar_sentences\n\u001b[1;32m----> 2\u001b[0m \u001b[43mget_similar_sentences\u001b[49m\u001b[43m(\u001b[49m\u001b[43murdu_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mur\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdegree_of_aug\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\inltk\\inltk.py:137\u001b[0m, in \u001b[0;36mget_similar_sentences\u001b[1;34m(sen, no_of_variations, language_code, degree_of_aug)\u001b[0m\n\u001b[0;32m    135\u001b[0m tok \u001b[38;5;241m=\u001b[39m LanguageTokenizer(language_code)\n\u001b[0;32m    136\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m tok\u001b[38;5;241m.\u001b[39mnumericalize(sen)\n\u001b[1;32m--> 137\u001b[0m embedding_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mget_embedding_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43msen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# get learner\u001b[39;00m\n\u001b[0;32m    139\u001b[0m defaults\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\inltk\\inltk.py:100\u001b[0m, in \u001b[0;36mget_embedding_vectors\u001b[1;34m(input, language_code)\u001b[0m\n\u001b[0;32m     98\u001b[0m defaults\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     99\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m--> 100\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mload_learner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlanguage_code\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m encoder \u001b[38;5;241m=\u001b[39m get_model(learn\u001b[38;5;241m.\u001b[39mmodel)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    102\u001b[0m encoder\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\fastai\\basic_train.py:619\u001b[0m, in \u001b[0;36mload_learner\u001b[1;34m(path, file, test, **db_kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoad a `Learner` object saved with `export_state` in `path/file` with empty data, optionally add `test` and load on `cpu`. `file` can be file-like (file or buffer)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    618\u001b[0m source \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m/\u001b[39mfile \u001b[38;5;28;01mif\u001b[39;00m is_pathlike(file) \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[1;32m--> 619\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m defaults\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(source)\n\u001b[0;32m    620\u001b[0m model \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    621\u001b[0m src \u001b[38;5;241m=\u001b[39m LabelLists\u001b[38;5;241m.\u001b[39mload_state(path, state\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\serialization.py:1028\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1027\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1028\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\serialization.py:1256\u001b[0m, in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1254\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1255\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1256\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1258\u001b[0m deserialized_storage_keys \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1260\u001b[0m offset \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;28;01mif\u001b[39;00m f_should_read_directly \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:349\u001b[0m, in \u001b[0;36mRNNBase.__setstate__\u001b[1;34m(self, d)\u001b[0m\n\u001b[0;32m    344\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights_names\u001b[38;5;241m.\u001b[39mextend(weights[:\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    346\u001b[0m                           \u001b[38;5;28;01mfor\u001b[39;00m wn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights_names]\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weight_refs \u001b[38;5;241m=\u001b[39m [weakref\u001b[38;5;241m.\u001b[39mref(w) \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 349\u001b[0m                           \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LSTM' object has no attribute '_flat_weights'"
     ]
    }
   ],
   "source": [
    "from inltk.inltk import get_similar_sentences\n",
    "get_similar_sentences(urdu_text, 5, 'ur', degree_of_aug = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a08a0e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LSTM' object has no attribute '_flat_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_similar_sentences\n\u001b[1;32m----> 3\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mget_similar_sentences\u001b[49m\u001b[43m(\u001b[49m\u001b[43murdu_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mur\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\inltk\\inltk.py:137\u001b[0m, in \u001b[0;36mget_similar_sentences\u001b[1;34m(sen, no_of_variations, language_code, degree_of_aug)\u001b[0m\n\u001b[0;32m    135\u001b[0m tok \u001b[38;5;241m=\u001b[39m LanguageTokenizer(language_code)\n\u001b[0;32m    136\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m tok\u001b[38;5;241m.\u001b[39mnumericalize(sen)\n\u001b[1;32m--> 137\u001b[0m embedding_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mget_embedding_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43msen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# get learner\u001b[39;00m\n\u001b[0;32m    139\u001b[0m defaults\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\inltk\\inltk.py:100\u001b[0m, in \u001b[0;36mget_embedding_vectors\u001b[1;34m(input, language_code)\u001b[0m\n\u001b[0;32m     98\u001b[0m defaults\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     99\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m--> 100\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mload_learner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlanguage_code\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m encoder \u001b[38;5;241m=\u001b[39m get_model(learn\u001b[38;5;241m.\u001b[39mmodel)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    102\u001b[0m encoder\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\fastai\\basic_train.py:619\u001b[0m, in \u001b[0;36mload_learner\u001b[1;34m(path, file, test, **db_kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoad a `Learner` object saved with `export_state` in `path/file` with empty data, optionally add `test` and load on `cpu`. `file` can be file-like (file or buffer)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    618\u001b[0m source \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m/\u001b[39mfile \u001b[38;5;28;01mif\u001b[39;00m is_pathlike(file) \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[1;32m--> 619\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m defaults\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(source)\n\u001b[0;32m    620\u001b[0m model \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    621\u001b[0m src \u001b[38;5;241m=\u001b[39m LabelLists\u001b[38;5;241m.\u001b[39mload_state(path, state\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\serialization.py:1028\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1027\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1028\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\serialization.py:1256\u001b[0m, in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1254\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1255\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1256\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1258\u001b[0m deserialized_storage_keys \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1260\u001b[0m offset \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;28;01mif\u001b[39;00m f_should_read_directly \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:349\u001b[0m, in \u001b[0;36mRNNBase.__setstate__\u001b[1;34m(self, d)\u001b[0m\n\u001b[0;32m    344\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights_names\u001b[38;5;241m.\u001b[39mextend(weights[:\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    346\u001b[0m                           \u001b[38;5;28;01mfor\u001b[39;00m wn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights_names]\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weight_refs \u001b[38;5;241m=\u001b[39m [weakref\u001b[38;5;241m.\u001b[39mref(w) \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 349\u001b[0m                           \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pythonUrdu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LSTM' object has no attribute '_flat_weights'"
     ]
    }
   ],
   "source": [
    "from inltk.inltk import get_similar_sentences\n",
    "\n",
    "output = get_similar_sentences(urdu_text, 5, 'ur')\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef03fad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonUrdu",
   "language": "python",
   "name": "pythonurdu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
